{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled0.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1kIGOdc3HqyUHHD1jjflVbhUxkZaPTvvw",
      "authorship_tag": "ABX9TyMtseL37Wx7pCCiHQ10p6rB",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/meitamerdianti123/RegisstGlowUp/blob/master/Untitled0.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DeT0RYiwi3Ou",
        "outputId": "6c29ec55-9161-4236-9c9d-eeb01ad7f704"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting split-folders\n",
            "  Downloading split_folders-0.5.1-py3-none-any.whl (8.4 kB)\n",
            "Installing collected packages: split-folders\n",
            "Successfully installed split-folders-0.5.1\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "!pip install split-folders"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "brj6zBrxi4Ms",
        "outputId": "59cacb3b-8f70-46a9-cafb-c30e9a3831cb"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import splitfolders\n",
        "splitfolders.ratio('/content/drive/MyDrive', output=\"./\", seed=1337, ratio=(.9, .1)) "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_6KAUCmZi4PZ",
        "outputId": "95cef96b-5358-4733-cd35-c45a4419697d"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Copying files: 800 files [00:10, 74.47 files/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_data_generator = keras.preprocessing.image.ImageDataGenerator(\n",
        "    horizontal_flip = True, vertical_flip = True, zoom_range = 0.1,\n",
        "    shear_range = 0.1, width_shift_range = 0.2, height_shift_range = 0.2, rotation_range = 90,\n",
        ")\n",
        "test_data_generator = keras.preprocessing.image.ImageDataGenerator()"
      ],
      "metadata": {
        "id": "4-LM3N1Ji4SE"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data = train_data_generator.flow_from_directory(\"./train\", target_size = (128, 128), batch_size = 1, shuffle = True)\n",
        "test_data = test_data_generator.flow_from_directory(\"./val\", target_size = (128,128), batch_size = 1, shuffle = True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D_2KS_91i4UW",
        "outputId": "07f82fcf-4332-4516-c27f-8bd7a7183e7e"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 720 images belonging to 8 classes.\n",
            "Found 80 images belonging to 8 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "labels =train_data.class_indices\n",
        "labels"
      ],
      "metadata": {
        "id": "VQfQGqlmkT0A",
        "outputId": "7e2cd9bc-6e85-4a58-f4c7-87d6290e2568",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'iu': 0,\n",
              " 'jaehyun': 1,\n",
              " 'jeno': 2,\n",
              " 'kareena': 3,\n",
              " 'kate': 4,\n",
              " 'obama': 5,\n",
              " 'reza': 6,\n",
              " 'rossa': 7}"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_array_from_datagen(train_generator):\n",
        "  x=[]\n",
        "  y=[]\n",
        "  train_generator.reset()\n",
        "  for i in range(train_generator.__len__()):\n",
        "    a,b=train_generator.next()\n",
        "    x.append(a)\n",
        "    y.append(b)\n",
        "  x=np.array(x, dtype = np.float32)\n",
        "  y=np.array(y, dtype = np.float32)\n",
        "  print(x.shape)\n",
        "  print(y.shape)\n",
        "  return x,y\n",
        "\n",
        "X_train, y_train = get_array_from_datagen(train_data)\n",
        "X_test, y_test = get_array_from_datagen(test_data)"
      ],
      "metadata": {
        "id": "5_AYT33PkT-2",
        "outputId": "14cd7486-0581-4539-9b55-200c49123b06",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(720, 1, 128, 128, 3)\n",
            "(720, 1, 8)\n",
            "(80, 1, 128, 128, 3)\n",
            "(80, 1, 8)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = X_train.reshape(-1, 128, 128, 3)\n",
        "X_test = X_test.reshape(-1, 128, 128, 3)\n",
        "y_train = y_train.reshape(-1, 8)\n",
        "y_test = y_test.reshape(-1, 8)"
      ],
      "metadata": {
        "id": "RIN2r0ppi4Wg"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import gc\n",
        "from keras import Sequential\n",
        "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, BatchNormalization, Dropout\n",
        "\n",
        "input_shape = (128, 128, 3)\n",
        "class_num = len(labels)\n",
        "\n",
        "def cnn1():\n",
        "    return Sequential([\n",
        "        Conv2D(64, kernel_size=(3, 3), activation='relu',padding='same',input_shape=input_shape),\n",
        "        BatchNormalization(),\n",
        "        MaxPooling2D(pool_size=(2, 2),strides=2),\n",
        "        Dropout(0.3),\n",
        "        Conv2D(64, kernel_size=(5, 5), activation='relu'),\n",
        "        MaxPooling2D(pool_size=(2, 2),strides=2),\n",
        "        Dropout(0.3),\n",
        "        Flatten(),\n",
        "        Dense(512, activation='relu'),\n",
        "        Dropout(0.3),\n",
        "        Dense(64, activation='relu'),\n",
        "        Dense(class_num, activation='softmax')\n",
        "    ])\n",
        "\n",
        "def cnn2():\n",
        "    return Sequential([\n",
        "        Conv2D(64, kernel_size=(3, 3), activation='relu',input_shape=input_shape),\n",
        "        BatchNormalization(),\n",
        "        MaxPooling2D(pool_size=(2, 2),strides=2),\n",
        "        Dropout(0.3),\n",
        "        Conv2D(64, kernel_size=(3, 3), activation='relu'),\n",
        "        Dropout(0.3),\n",
        "        MaxPooling2D(pool_size=(2, 2),strides=2),\n",
        "        Conv2D(64, kernel_size=(3, 3), activation='relu'),\n",
        "        Dropout(0.3),\n",
        "        MaxPooling2D(pool_size=(2, 2),strides=2),\n",
        "        Flatten(),\n",
        "        Dense(128, activation='relu'),\n",
        "        Dense(class_num, activation='softmax')\n",
        "    ])\n",
        "\n",
        "def cnn3():\n",
        "    return Sequential([\n",
        "        Conv2D(128, kernel_size=(3, 3), activation='relu',padding='same',input_shape=input_shape),\n",
        "        BatchNormalization(),\n",
        "        Conv2D(128, kernel_size=(3, 3), activation='relu',padding='same'),\n",
        "        Dropout(0.3),\n",
        "        MaxPooling2D(pool_size=(2, 2),strides=2),\n",
        "        Conv2D(128, kernel_size=(3, 3), activation='relu'),\n",
        "        Dropout(0.3),\n",
        "        Conv2D(128, kernel_size=(3, 3), activation='relu'),\n",
        "        Dropout(0.3),\n",
        "        MaxPooling2D(pool_size=(2, 2),strides=2),\n",
        "        Flatten(),\n",
        "        Dense(128, activation='relu'),\n",
        "        Dense(class_num, activation='softmax')\n",
        "    ])"
      ],
      "metadata": {
        "id": "Ob9sWg9pk0Ye"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "learning_rate_reduction = keras.callbacks.ReduceLROnPlateau(\n",
        "    monitor = \"val_accuracy\",\n",
        "    factor = 0.5,\n",
        "    patience = 3,\n",
        "    verbose = 0,\n",
        "    min_lr = 0.00001\n",
        ")\n",
        "early_stopping = keras.callbacks.EarlyStopping(patience=5, verbose=1)"
      ],
      "metadata": {
        "id": "LcqiOJ1fk0eM"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "def plot_history(history):\n",
        "    plt.plot(history.history['accuracy'])\n",
        "    plt.plot(history.history['val_accuracy'])\n",
        "    plt.title('model accuracy')\n",
        "    plt.ylabel('accuracy')\n",
        "    plt.xlabel('epoch')\n",
        "    plt.legend(['train', 'test'], loc='upper left')\n",
        "    plt.show()\n",
        "    # summarize history for loss\n",
        "    plt.plot(history.history['loss'])\n",
        "    plt.plot(history.history['val_loss'])\n",
        "    plt.title('model loss')\n",
        "    plt.ylabel('loss')\n",
        "    plt.xlabel('epoch')\n",
        "    plt.legend(['train', 'test'], loc='upper left')\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "c_PtyA38k0jg"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = cnn1()\n",
        "model.compile(optimizer=\"Adam\", loss=[\"categorical_crossentropy\"], metrics = [\"accuracy\"])\n",
        "history = model.fit(X_train, y_train ,epochs=25, validation_data=(X_test, y_test),\n",
        "                    verbose=2, callbacks = [learning_rate_reduction, early_stopping])\n",
        "gc.collect()"
      ],
      "metadata": {
        "id": "850Iu6xdk0ob",
        "outputId": "e41c5f11-753c-4ea7-bf0c-da1746cf9e8d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/25\n",
            "23/23 - 77s - loss: 17.5262 - accuracy: 0.1208 - val_loss: 2.0794 - val_accuracy: 0.1250 - lr: 0.0010 - 77s/epoch - 3s/step\n",
            "Epoch 2/25\n",
            "23/23 - 74s - loss: 2.1962 - accuracy: 0.1222 - val_loss: 2.0795 - val_accuracy: 0.1250 - lr: 0.0010 - 74s/epoch - 3s/step\n",
            "Epoch 3/25\n",
            "23/23 - 76s - loss: 2.1438 - accuracy: 0.1208 - val_loss: 2.0795 - val_accuracy: 0.1250 - lr: 0.0010 - 76s/epoch - 3s/step\n",
            "Epoch 4/25\n",
            "23/23 - 78s - loss: 2.1055 - accuracy: 0.1236 - val_loss: 2.0795 - val_accuracy: 0.1250 - lr: 0.0010 - 78s/epoch - 3s/step\n",
            "Epoch 5/25\n"
          ]
        }
      ]
    }
  ]
}